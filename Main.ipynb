{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "065c6c2e",
   "metadata": {},
   "source": [
    "# SMS Spam Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3131d89a",
   "metadata": {},
   "source": [
    "Natural Language Processing (COMP6576001) - LA01 - Kelompok 7\n",
    "\n",
    "- Nadya Tyandra (2440032820)\n",
    "- Randy Antonio (2440034170)\n",
    "- Farrel Rasyad (2440048560)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade01cf",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70e917e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "import tkinter as tk\n",
    "import tkinter.font as TkFont"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8390d8d2",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7510afb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teks</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PROMO] Beli paket Flash mulai 1GB di MY TELKO...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5 GB/30 hari hanya Rp 35 Ribu Spesial buat A...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-08 11:47:11.Plg Yth, sisa kuota Flash ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-08-07 11:29:47.Plg Yth, sisa kuota Flash ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.5GB/30 hari hanya Rp 55 Ribu Spesial buat an...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>Yooo sama2, oke nanti aku umumin di grup kelas</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>游때 sebelumnya ga ad nulis kerudung. Kirain warn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>Mba mau kirim 300 ya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>nama1  beaok bwrangkat pagi...mau cas atay tra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>No bri atas nama kamu mana</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1143 rows 칑 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Teks  label\n",
       "0     [PROMO] Beli paket Flash mulai 1GB di MY TELKO...      2\n",
       "1     2.5 GB/30 hari hanya Rp 35 Ribu Spesial buat A...      2\n",
       "2     2016-07-08 11:47:11.Plg Yth, sisa kuota Flash ...      2\n",
       "3     2016-08-07 11:29:47.Plg Yth, sisa kuota Flash ...      2\n",
       "4     4.5GB/30 hari hanya Rp 55 Ribu Spesial buat an...      2\n",
       "...                                                 ...    ...\n",
       "1138     Yooo sama2, oke nanti aku umumin di grup kelas      0\n",
       "1139  游때 sebelumnya ga ad nulis kerudung. Kirain warn...      0\n",
       "1140                               Mba mau kirim 300 ya      0\n",
       "1141  nama1  beaok bwrangkat pagi...mau cas atay tra...      0\n",
       "1142                         No bri atas nama kamu mana      0\n",
       "\n",
       "[1143 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('dataset/dataset_sms_spam_v1.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98067cd9",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ceb786",
   "metadata": {},
   "source": [
    "### 3.1 Data Preprocessing - Case Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70ac4c01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teks</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[promo] beli paket flash mulai 1gb di my telko...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5 gb/30 hari hanya rp 35 ribu spesial buat a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-08 11:47:11.plg yth, sisa kuota flash ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-08-07 11:29:47.plg yth, sisa kuota flash ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.5gb/30 hari hanya rp 55 ribu spesial buat an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>yooo sama2, oke nanti aku umumin di grup kelas</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>游때 sebelumnya ga ad nulis kerudung. kirain warn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>mba mau kirim 300 ya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>nama1  beaok bwrangkat pagi...mau cas atay tra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>no bri atas nama kamu mana</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1143 rows 칑 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Teks  label\n",
       "0     [promo] beli paket flash mulai 1gb di my telko...      1\n",
       "1     2.5 gb/30 hari hanya rp 35 ribu spesial buat a...      1\n",
       "2     2016-07-08 11:47:11.plg yth, sisa kuota flash ...      1\n",
       "3     2016-08-07 11:29:47.plg yth, sisa kuota flash ...      1\n",
       "4     4.5gb/30 hari hanya rp 55 ribu spesial buat an...      1\n",
       "...                                                 ...    ...\n",
       "1138     yooo sama2, oke nanti aku umumin di grup kelas      0\n",
       "1139  游때 sebelumnya ga ad nulis kerudung. kirain warn...      0\n",
       "1140                               mba mau kirim 300 ya      0\n",
       "1141  nama1  beaok bwrangkat pagi...mau cas atay tra...      0\n",
       "1142                         no bri atas nama kamu mana      0\n",
       "\n",
       "[1143 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].replace({1 : 2}, inplace=True)\n",
    "data.loc[data[\"label\"] == 2, \"label\"] = 1\n",
    "data.dropna(inplace=True)\n",
    "data['Teks'] = data['Teks'].str.lower()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e239ce91",
   "metadata": {},
   "source": [
    "### 3.2 Data Preprocessing - Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cca9f99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def remove_http(s):\n",
    "    return re.sub(r'http:[^\\s]+|https:[^\\s]+|www.[^\\s]+', ' ', s)\n",
    "\n",
    "def remove_hashtag(s):\n",
    "    return re.sub(r'#[\\w\\d]+', ' hashtag ', s)\n",
    "\n",
    "def remove_punc(s):\n",
    "    return re.sub(r'[^\\w\\s]', ' ', s)\n",
    "\n",
    "def remove_number(s):\n",
    "    return re.sub(r'\\d+', ' ', s)\n",
    "\n",
    "def remove_spaces(s):\n",
    "    return re.sub(r'\\s{2,}', ' ', s)\n",
    "\n",
    "def remove_newline(s):\n",
    "    return re.sub(r'\\\\n{1}', ' ', s)\n",
    "\n",
    "def remove_leadingspace(s):\n",
    "    return s.strip()\n",
    "\n",
    "def clean_data(data):\n",
    "    data['Teks'] = data['Teks'].apply(lambda x: remove_http(x))\n",
    "    data['Teks'] = data['Teks'].apply(lambda x: remove_hashtag(x))\n",
    "    data['Teks'] = data['Teks'].apply(lambda x: remove_punc(x))\n",
    "    data['Teks'] = data['Teks'].apply(lambda x: remove_number(x))\n",
    "    data['Teks'] = data['Teks'].apply(lambda x: remove_spaces(x))\n",
    "    data['Teks'] = data['Teks'].apply(lambda x: remove_newline(x))\n",
    "    data['Teks'] = data['Teks'].apply(lambda x: remove_leadingspace(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8178ae75",
   "metadata": {},
   "source": [
    "### 3.3 Data Preprocessing - Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65c12689",
   "metadata": {},
   "outputs": [],
   "source": [
    "kamus1 = pd.read_csv('dataset/new_kamusalay.csv', encoding=\"ISO-8859-1\", names=['nonformal', 'formal'])\n",
    "kamus2 = pd.read_csv('dataset/colloquial-indonesian-lexicon.csv', encoding=\"ISO-8859-1\", usecols=['slang', 'formal'])\n",
    "kamus2 = kamus2.rename(columns={'slang': 'nonformal'})\n",
    "\n",
    "def normalize(data, kamusNormalisasi):\n",
    "    for index in range(len(data)):\n",
    "        d = kamusNormalisasi.set_index('nonformal')['formal'].to_dict()\n",
    "        p = re.compile(r'\\b(' + '|'.join(d.keys()) + r')\\b')\n",
    "        b = p.sub(lambda x: d[x.group()], data.Teks.iloc[index])\n",
    "        data.loc[index, 'Teks'] = b\n",
    "        \n",
    "def normalization(data):\n",
    "    normalize(data, kamus1)\n",
    "    normalize(data, kamus2)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899bddaa",
   "metadata": {},
   "source": [
    "### 3.4 Data Preprocessing - Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73fb5d73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "def stemming(data):\n",
    "    for index in range(len(data)):\n",
    "        sentence = data['Teks'].iloc[index]\n",
    "        data.loc[index, 'Teks'] = stemmer.stem(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0426ec1a",
   "metadata": {},
   "source": [
    "### 3.5 Data Preprocessing - Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a269483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sw(dt, factory, stopword):\n",
    "    for i in range(len(dt)):\n",
    "        sentence = dt['Teks'].iloc[i]\n",
    "        dt.loc[i, 'Teks'] = stopword.remove(sentence)\n",
    "        \n",
    "def stopword(data):\n",
    "    factory = StopWordRemoverFactory()\n",
    "    stopword = factory.create_stop_word_remover()\n",
    "    remove_sw(data, factory, stopword)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e5eb5e",
   "metadata": {},
   "source": [
    "### 3.6 Data Preprocessing - Removing Data that Have Less than or Equal 3 Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0a942ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_three_words(data):\n",
    "    data['len'] = data['Teks'].apply(lambda x: len(x.split()))\n",
    "    data = data[~data['len'].isin([1,2,3])]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a92cd",
   "metadata": {},
   "source": [
    "## 4. Feature Extraction, Classification, and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8279b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = None\n",
    "lr = None\n",
    "precision = None\n",
    "recall = None\n",
    "accuracy = None\n",
    "f1 = None\n",
    "\n",
    "def splitting(data):\n",
    "    x = data['Teks']\n",
    "    y = data['label']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def vectorizing(x_train, x_test):\n",
    "    global vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    x_train_vector = vectorizer.fit_transform(x_train)\n",
    "    x_test_vector = vectorizer.transform(x_test)\n",
    "    return x_train_vector, x_test_vector\n",
    "\n",
    "def modelling(data):\n",
    "    global lr\n",
    "    global precision\n",
    "    global recall\n",
    "    global accuracy\n",
    "    global f1\n",
    "    x_train, x_test, y_train, y_test = splitting(data)\n",
    "    x_train_vector, x_test_vector = vectorizing(x_train, x_test)\n",
    "    lr = LogisticRegression(random_state = 0).fit(x_train_vector, y_train)\n",
    "    y_pred = lr.predict(x_test_vector)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f784d57e",
   "metadata": {},
   "source": [
    "## 5. GUI Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "576dc45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = None\n",
    "input_data = None\n",
    "\n",
    "def buildGUI():\n",
    "    root = tk.Tk()\n",
    "\n",
    "    root.title(\"SMS Spam Detector\")\n",
    "    root.iconbitmap(r'asset/spam.ico')\n",
    "    root.geometry('900x600')\n",
    "    root.resizable(width = False, height = False)\n",
    "\n",
    "    header = TkFont.Font(family = \"San Francisco\", size = 24, weight = \"bold\")\n",
    "    subheader = TkFont.Font(family = \"San Francisco\", size = 10)\n",
    "    body = TkFont.Font(family = \"San Francisco\", size = 8)\n",
    "\n",
    "    canvas1 = tk.Canvas(root, width = 900, height = 600)\n",
    "    canvas1.pack()\n",
    "\n",
    "    title = tk.Label(text = \"SMS Spam Detector\", font = header)\n",
    "    canvas1.create_window(450, 40, window = title)\n",
    "\n",
    "    # Input text\n",
    "    input_label = tk.Label(root, text = \"Input text\", font = subheader).place(x = 40, y = 120)\n",
    "    input_entry = tk.Text(root, height = 4, width = 40)\n",
    "    canvas1.create_window(360, 130, window = input_entry)\n",
    "    \n",
    "    # After text cleaning\n",
    "    cleaning_label = tk.Label(root, text = \"After text cleaning\", font = subheader).place(x = 40, y = 270)\n",
    "    cleaning_entry = tk.Text(root, height = 4, width = 40, state = tk.DISABLED)\n",
    "    canvas1.create_window(360, 280, window = cleaning_entry)\n",
    "    \n",
    "    # After normalization\n",
    "    nor_label = tk.Label(root, text = \"After normalization\", font = subheader).place(x = 40, y = 360)\n",
    "    nor_entry = tk.Text(root, height = 4, width = 40, state = tk.DISABLED)\n",
    "    canvas1.create_window(360, 370, window = nor_entry)\n",
    "    \n",
    "    # After stemming\n",
    "    stemming_label = tk.Label(root, text = \"After stemming\", font = subheader).place(x = 40, y = 450)\n",
    "    stemming_entry = tk.Text(root, height = 4, width = 40, state = tk.DISABLED)\n",
    "    canvas1.create_window(360, 460, window = stemming_entry)\n",
    "    \n",
    "    # Credit\n",
    "    credit = tk.Label(text = \"Kelompok 7 - Nadya Tyandra (2440032820), Randy Antonio (2440034170), Farrel Rasyad (2440048560) - Natural Language Processing (COMP6576001) - LA01\", font = body)\n",
    "    canvas1.create_window(450, 590, window = credit)\n",
    "    \n",
    "    def applyPreprocessing():\n",
    "        global input_text\n",
    "        global input_data\n",
    "        input_text = str(input_entry.get(\"1.0\", tk.END))\n",
    "        input_data = pd.DataFrame({'Teks': [input_text]})\n",
    "        \n",
    "        input_data = clean_data(input_data)\n",
    "        cleaning_entry['state'] = tk.NORMAL\n",
    "        cleaning_entry.delete(\"1.0\", tk.END)\n",
    "        cleaning_output = input_data.iat[0,0]\n",
    "        cleaning_entry.insert(tk.END, cleaning_output)\n",
    "        cleaning_entry['state'] = tk.DISABLED\n",
    "        \n",
    "        normalization(input_data)\n",
    "        nor_entry['state'] = tk.NORMAL\n",
    "        nor_entry.delete(\"1.0\", tk.END)\n",
    "        nor_output = input_data.iat[0,0]\n",
    "        nor_entry.insert(tk.END, nor_output)\n",
    "        nor_entry['state'] = tk.DISABLED\n",
    "        \n",
    "        stemming(input_data)\n",
    "        stemming_entry['state'] = tk.NORMAL\n",
    "        stemming_entry.delete(\"1.0\", tk.END)\n",
    "        stemming_output = input_data.iat[0,0]\n",
    "        stemming_entry.insert(tk.END, stemming_output)\n",
    "        stemming_entry['state'] = tk.DISABLED\n",
    "        \n",
    "        button2['state'] = tk.NORMAL\n",
    "    \n",
    "    button1 = tk.Button(root, text = \"Apply Preprocessing\", font = subheader, command = applyPreprocessing, fg = \"white\", bg = \"black\", activebackground = \"white\", activeforeground = \"black\")\n",
    "    canvas1.create_window(290, 200, window = button1)\n",
    "    \n",
    "    def makePrediction():\n",
    "        vect = vectorizer.transform(input_data['Teks'])\n",
    "        pred = lr.predict(vect)\n",
    "        output_label2 = tk.Label(root, text = \"             \", font = header, fg = \"black\").place(x = 650, y = 170)\n",
    "        if(pred == 1):\n",
    "            output_label = tk.Label(root, text = \"Spam\", font = header, fg = \"red\").place(x = 657, y = 170)\n",
    "        elif(pred == 0):\n",
    "            output_label = tk.Label(root, text = \"Ham\", font = header, fg = \"green\").place(x = 665, y = 170)\n",
    "       \n",
    "        model_info_label = tk.Label(root, text = 'Model Information', font = subheader).place(x = 650, y = 215)\n",
    "        algorithm_label = tk.Label(root, text = 'Algorithm: TF-IDF Vectorizer and Logistic Regression', font = subheader).place(x = 550, y = 245)\n",
    "        splitting_label = tk.Label(root, text = 'Splitting ratio: 80% : 20%', font = subheader).place(x = 550, y = 275)\n",
    "        precision_label = tk.Label(root, text = 'Precision: ' + str(precision), font = subheader).place(x = 550, y = 305)\n",
    "        recall_label = tk.Label(root, text = 'Recall: ' + str(recall), font = subheader).place(x = 550, y = 335)\n",
    "        accuracy_label = tk.Label(root, text = 'Accuracy: ' + str(accuracy), font = subheader).place(x = 550, y = 365)\n",
    "        f1_label = tk.Label(root, text = 'F1-Score: ' + str(f1), font = subheader).place(x = 550, y = 395)\n",
    "        \n",
    "    button2 = tk.Button(root, text = \"Make Prediction\", font = subheader, command = makePrediction, fg = \"white\", bg = \"black\", activebackground = \"white\", activeforeground = \"black\", state = tk.DISABLED)\n",
    "    canvas1.create_window(290, 530, window = button2)\n",
    "\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd637939",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = clean_data(data)\n",
    "    normalization(data)\n",
    "    stemming(data)\n",
    "    data = stopword(data)\n",
    "    data = remove_three_words(data)\n",
    "    modelling(data)\n",
    "    buildGUI()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
